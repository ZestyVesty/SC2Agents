FIX: check up on loss and target
FIX: check if memory will be lost if restarting to train a model


######################################  Dueling_DQN ##################################################
General flow of DDQN

state: player_relative -> (84,84) array, which is the feature screen

check if move_screen is available or not:
    No  ->  Selects army
    Yes ->  1. get the state
            2. is this run in training mode?
                No  ->  Use the trained model to make decisions
                Yes ->  1. Predict the next action and xy coordinate using EGAS, this action will be used
                        2. Update the online DQN and network used to estimate TD targets                                <- Not looked into
                        3. Add experience to memory                                                                     <- Not looked into
                            - includes adding: last_state, last_action, reward of that observation and state
                        4. Update the last state and last action
            3. check if the action chosen is not randomly generated
                Yes -> attack the generated xy coordinate
                No  -> move to the generated xy coordinate


########################## _epsilon_greedy_action_selection (EGAS) ###########################################
Choose action from state with epsilon greedy strategy.
This function returns the xy coordinate and a string. This string is "random" or "nonrandom"


1. Set the value of the epsilon
    Note:   the epsilon value will be chosen between the minimum value it can be, or
            the value that is decayed depending on the number of steps into the mini game

            Eventually epsilon will equal to a preset value (epsilon_min), to make sure it doesn't become too small

2. is epsilon bigger than a random number generated between 0 and 1?
    Yes ->  randomly generate x and y, for each choose a random number between 0 and feature_screen_size, and return "random"
    No  ->  generate the Q values by starting the session "run"



